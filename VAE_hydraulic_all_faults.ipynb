{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from VAE1D import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.debugger import set_trace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define train function in notebook due to import namespace bug."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_VAE1D(dl):\n",
    "    \"\"\"\n",
    "    Execute the training loop\n",
    "    \"\"\"\n",
    "    loss_tracker = AvgTracker()\n",
    "    kl_tracker = AvgTracker()\n",
    "    logp_tracker = AvgTracker()\n",
    "    timer = StopWatch()\n",
    "    freq = min(log_freq, len(dl))\n",
    "    \n",
    "    for i, (X, _) in enumerate(tqdm(dl)):\n",
    "        \n",
    "        X = X.to(device)\n",
    "        timer.lap()  # load time\n",
    "        \n",
    "        # Generate transient and compute loss\n",
    "        X_hat, mu, logvar = model(X)\n",
    "        loss, loss_desc = criterion(X_hat, X, mu, logvar)\n",
    "        timer.lap()  # gen time\n",
    "        \n",
    "        loss_tracker.update(loss.item())\n",
    "        kl_tracker.update(loss_desc['KL'].item())\n",
    "        logp_tracker.update(loss_desc['logp'].item())\n",
    "        \n",
    "        if model.training:\n",
    "            # Update weights\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            timer.lap()  # backprop time\n",
    "        \n",
    "        if ((i + 1) % freq == 0) and ((epoch + 1) % ep_freq == 0):\n",
    "            # Print progress\n",
    "            if not model.training:\n",
    "                print('VALIDATION')\n",
    "            print(f'Epoch: {epoch + 1} ({i + 1}/{len(dl)})')\n",
    "            print(f'\\tData load time: {timer.elapsed[0]:.3f} sec')\n",
    "            print(f'\\tGeneration time: {timer.elapsed[1]:.3f} sec')\n",
    "            if model.training:\n",
    "                print(f'\\tBackprop time: {timer.elapsed[2]:.3f} sec')\n",
    "            print(f'\\tLog probability: {logp_tracker.val:.4f} '\n",
    "                  f'(avg {logp_tracker.avg:.4f})')\n",
    "            print(f'\\tKL: {kl_tracker.val:.4f} (avg {kl_tracker.avg:.4f})')\n",
    "            print(f'\\tLoss: {loss_tracker.val:.4f} (avg {loss_tracker.avg:.4f})')\n",
    "\n",
    "    return loss_tracker.avg, kl_tracker.avg, logp_tracker.avg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accumulator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build model and loss function \n",
    "Initially designed for 2D input images, modified for 1D time-series data.\n",
    "Based on this paper: https://arxiv.org/abs/1807.01349"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The hydraulic system has 14 sensors from which to pull data\n",
    "n_channels = 14\n",
    "# The data has been resized to 512, although it represents 1 min for each cycle\n",
    "size = 512\n",
    "# Latent space is restricted to be about 1/170th of the input dims, similar to 2D case\n",
    "n_latent = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VAE1D(size, n_channels, n_latent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = 1  # KL term relative weight\n",
    "criterion = VAE1DLoss(beta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load hydraulic test data\n",
    "From this dataset: https://archive.ics.uci.edu/ml/datasets/Condition+monitoring+of+hydraulic+systems#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc = 'accumulator'\n",
    "data_path = Path(f'data/hydraulic/{desc}/')\n",
    "batch_size = 32\n",
    "train_dl, val_dl, test_dl = load_datasets(data_path,\n",
    "                                          batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_dl), len(val_dl), len(test_dl))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display settings - TODO add Visdom logging\n",
    "log_freq = 15 # batches\n",
    "ep_freq = 10  # epochs\n",
    "\n",
    "# Training parameters\n",
    "epochs = 300\n",
    "lr = 1e-3\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Checkpoint to resume from (default None)\n",
    "load_path = None\n",
    "\n",
    "# Checkpoint save location\n",
    "save_path = Path(f\"models/{date.today().strftime('%y%m%d')}-{desc}/\")\n",
    "if save_path.is_dir():\n",
    "    print(f\"Folder {save_path} already exists\")\n",
    "else:\n",
    "    os.mkdir(save_path)\n",
    "save_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load checkpoint if any\n",
    "if load_path is not None:\n",
    "    checkpoint = torch.load(load_path, map_location=device)\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "    print(\"Checkpoint loaded\")\n",
    "    print(f\"Validation loss: {checkpoint['val_loss']}\")\n",
    "    print(f\"Epoch: {checkpoint['epoch']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load optimizer and scheduler\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move to GPU\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main loop\n",
    "best_loss = np.inf\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    model.train()\n",
    "    scheduler.step()\n",
    "    train_loss, train_kl, train_logp = train_VAE1D(train_dl)\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_loss, val_kl, val_logp = train_VAE1D(val_dl)\n",
    "\n",
    "    # Report training progress to user\n",
    "    if val_loss < best_loss:\n",
    "        print('Saving checkpoint..')\n",
    "        best_loss = val_loss\n",
    "        save_dict = {'epoch': epoch + 1,\n",
    "                     'state_dict': model.state_dict(),\n",
    "                     'val_loss': val_loss,\n",
    "                     'optimizer': optimizer.state_dict()}\n",
    "        path = save_path / f'best_model-{n_latent}-{beta}.pt'\n",
    "        torch.save(save_dict, path)\n",
    "        print(f'Lowest validation loss: {best_loss:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cooler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build model and loss function \n",
    "Initially designed for 2D input images, modified for 1D time-series data.\n",
    "Based on this paper: https://arxiv.org/abs/1807.01349"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The hydraulic system has 14 sensors from which to pull data\n",
    "n_channels = 14\n",
    "# The data has been resized to 512, although it represents 1 min for each cycle\n",
    "size = 512\n",
    "# Latent space is restricted to be about 1/170th of the input dims, similar to 2D case\n",
    "n_latent = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VAE1D(size, n_channels, n_latent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = 1  # KL term relative weight\n",
    "criterion = VAE1DLoss(beta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load hydraulic test data\n",
    "From this dataset: https://archive.ics.uci.edu/ml/datasets/Condition+monitoring+of+hydraulic+systems#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc = 'cooler'\n",
    "data_path = Path(f'data/hydraulic/{desc}/')\n",
    "batch_size = 32\n",
    "train_dl, val_dl, test_dl = load_datasets(data_path,\n",
    "                                          batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_dl), len(val_dl), len(test_dl))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display settings - TODO add Visdom logging\n",
    "log_freq = 15 # batches\n",
    "ep_freq = 10  # epochs\n",
    "\n",
    "# Training parameters\n",
    "epochs = 300\n",
    "lr = 1e-3\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Checkpoint to resume from (default None)\n",
    "load_path = None\n",
    "\n",
    "# Checkpoint save location\n",
    "save_path = Path(f\"models/{date.today().strftime('%y%m%d')}-{desc}/\")\n",
    "if save_path.is_dir():\n",
    "    print(f\"Folder {save_path} already exists\")\n",
    "else:\n",
    "    os.mkdir(save_path)\n",
    "save_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load checkpoint if any\n",
    "if load_path is not None:\n",
    "    checkpoint = torch.load(load_path, map_location=device)\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "    print(\"Checkpoint loaded\")\n",
    "    print(f\"Validation loss: {checkpoint['val_loss']}\")\n",
    "    print(f\"Epoch: {checkpoint['epoch']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load optimizer and scheduler\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move to GPU\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main loop\n",
    "best_loss = np.inf\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    model.train()\n",
    "    scheduler.step()\n",
    "    train_loss, train_kl, train_logp = train_VAE1D(train_dl)\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_loss, val_kl, val_logp = train_VAE1D(val_dl)\n",
    "\n",
    "    # Report training progress to user\n",
    "    if val_loss < best_loss:\n",
    "        print('Saving checkpoint..')\n",
    "        best_loss = val_loss\n",
    "        save_dict = {'epoch': epoch + 1,\n",
    "                     'state_dict': model.state_dict(),\n",
    "                     'val_loss': val_loss,\n",
    "                     'optimizer': optimizer.state_dict()}\n",
    "        path = save_path / f'best_model-{n_latent}-{beta}.pt'\n",
    "        torch.save(save_dict, path)\n",
    "        print(f'Lowest validation loss: {best_loss:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pump"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build model and loss function \n",
    "Initially designed for 2D input images, modified for 1D time-series data.\n",
    "Based on this paper: https://arxiv.org/abs/1807.01349"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The hydraulic system has 14 sensors from which to pull data\n",
    "n_channels = 14\n",
    "# The data has been resized to 512, although it represents 1 min for each cycle\n",
    "size = 512\n",
    "# Latent space is restricted to be about 1/170th of the input dims, similar to 2D case\n",
    "n_latent = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VAE1D(size, n_channels, n_latent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = 1  # KL term relative weight\n",
    "criterion = VAE1DLoss(beta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load hydraulic test data\n",
    "From this dataset: https://archive.ics.uci.edu/ml/datasets/Condition+monitoring+of+hydraulic+systems#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc = 'pump'\n",
    "data_path = Path(f'data/hydraulic/{desc}/')\n",
    "batch_size = 32\n",
    "train_dl, val_dl, test_dl = load_datasets(data_path,\n",
    "                                          batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_dl), len(val_dl), len(test_dl))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display settings - TODO add Visdom logging\n",
    "log_freq = 15 # batches\n",
    "ep_freq = 10  # epochs\n",
    "\n",
    "# Training parameters\n",
    "epochs = 300\n",
    "lr = 1e-3\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Checkpoint to resume from (default None)\n",
    "load_path = None\n",
    "\n",
    "# Checkpoint save location\n",
    "save_path = Path(f\"models/{date.today().strftime('%y%m%d')}-{desc}/\")\n",
    "if save_path.is_dir():\n",
    "    print(f\"Folder {save_path} already exists\")\n",
    "else:\n",
    "    os.mkdir(save_path)\n",
    "save_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load checkpoint if any\n",
    "if load_path is not None:\n",
    "    checkpoint = torch.load(load_path, map_location=device)\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "    print(\"Checkpoint loaded\")\n",
    "    print(f\"Validation loss: {checkpoint['val_loss']}\")\n",
    "    print(f\"Epoch: {checkpoint['epoch']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load optimizer and scheduler\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move to GPU\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main loop\n",
    "best_loss = np.inf\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    model.train()\n",
    "    scheduler.step()\n",
    "    train_loss, train_kl, train_logp = train_VAE1D(train_dl)\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_loss, val_kl, val_logp = train_VAE1D(val_dl)\n",
    "\n",
    "    # Report training progress to user\n",
    "    if val_loss < best_loss:\n",
    "        print('Saving checkpoint..')\n",
    "        best_loss = val_loss\n",
    "        save_dict = {'epoch': epoch + 1,\n",
    "                     'state_dict': model.state_dict(),\n",
    "                     'val_loss': val_loss,\n",
    "                     'optimizer': optimizer.state_dict()}\n",
    "        path = save_path / f'best_model-{n_latent}-{beta}.pt'\n",
    "        torch.save(save_dict, path)\n",
    "        print(f'Lowest validation loss: {best_loss:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Valve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build model and loss function \n",
    "Initially designed for 2D input images, modified for 1D time-series data.\n",
    "Based on this paper: https://arxiv.org/abs/1807.01349"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The hydraulic system has 14 sensors from which to pull data\n",
    "n_channels = 14\n",
    "# The data has been resized to 512, although it represents 1 min for each cycle\n",
    "size = 512\n",
    "# Latent space is restricted to be about 1/170th of the input dims, similar to 2D case\n",
    "n_latent = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VAE1D(size, n_channels, n_latent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = 1  # KL term relative weight\n",
    "criterion = VAE1DLoss(beta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load hydraulic test data\n",
    "From this dataset: https://archive.ics.uci.edu/ml/datasets/Condition+monitoring+of+hydraulic+systems#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc = 'valve'\n",
    "data_path = Path(f'data/hydraulic/{desc}/')\n",
    "batch_size = 32\n",
    "train_dl, val_dl, test_dl = load_datasets(data_path,\n",
    "                                          batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_dl), len(val_dl), len(test_dl))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display settings - TODO add Visdom logging\n",
    "log_freq = 15 # batches\n",
    "ep_freq = 10  # epochs\n",
    "\n",
    "# Training parameters\n",
    "epochs = 300\n",
    "lr = 1e-3\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Checkpoint to resume from (default None)\n",
    "load_path = None\n",
    "\n",
    "# Checkpoint save location\n",
    "save_path = Path(f\"models/{date.today().strftime('%y%m%d')}-{desc}/\")\n",
    "if save_path.is_dir():\n",
    "    print(f\"Folder {save_path} already exists\")\n",
    "else:\n",
    "    os.mkdir(save_path)\n",
    "save_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load checkpoint if any\n",
    "if load_path is not None:\n",
    "    checkpoint = torch.load(load_path, map_location=device)\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "    print(\"Checkpoint loaded\")\n",
    "    print(f\"Validation loss: {checkpoint['val_loss']}\")\n",
    "    print(f\"Epoch: {checkpoint['epoch']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load optimizer and scheduler\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move to GPU\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main loop\n",
    "best_loss = np.inf\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    model.train()\n",
    "    scheduler.step()\n",
    "    train_loss, train_kl, train_logp = train_VAE1D(train_dl)\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_loss, val_kl, val_logp = train_VAE1D(val_dl)\n",
    "\n",
    "    # Report training progress to user\n",
    "    if val_loss < best_loss:\n",
    "        print('Saving checkpoint..')\n",
    "        best_loss = val_loss\n",
    "        save_dict = {'epoch': epoch + 1,\n",
    "                     'state_dict': model.state_dict(),\n",
    "                     'val_loss': val_loss,\n",
    "                     'optimizer': optimizer.state_dict()}\n",
    "        path = save_path / f'best_model-{n_latent}-{beta}.pt'\n",
    "        torch.save(save_dict, path)\n",
    "        print(f'Lowest validation loss: {best_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
