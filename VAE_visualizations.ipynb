{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from VAE1D import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.debugger import set_trace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: ADD VISUALIZATIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO include in epoch loop?\n",
    "# TODO look into what the scheduler is for\n",
    "# visualize reconst and free sample\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    val_iter = iter(val_dl)\n",
    "\n",
    "    # Generate 25 images\n",
    "    imgs = val_iter._get_batch()[1][0][:25]\n",
    "    imgs = imgs.to(device)\n",
    "    gen_imgs, mu, logvar = model(imgs)\n",
    "    \n",
    "    # Scale images back to 0-1\n",
    "    imgs = (imgs + 1) / 2\n",
    "    grid = make_grid(imgs, nrow=5, padding=20)\n",
    "    gen_imgs = (gen_imgs + 1) / 2\n",
    "    gen_grid = make_grid(gen_imgs, nrow=5, padding=20)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "grid = grid.cpu()\n",
    "gen_grid = gen_grid.cpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.imshow(grid.permute(1, 2, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.imshow(gen_grid.permute(1, 2, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mu = mu.cpu()\n",
    "std = (0.5 * logvar).exp().cpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for i in np.random.choice(range(mu.shape[0]), 5):\n",
    "    plt.figure()\n",
    "    mu_eg = mu[i, :].squeeze(-1).squeeze(-1)\n",
    "    plt.plot(mu_eg.numpy())\n",
    "    plt.figure()\n",
    "    std_eg = std[i, :].squeeze(-1).squeeze(-1)\n",
    "    plt.plot(std_eg.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with torch.no_grad():\n",
    "    # Generate some random images\n",
    "    noises = torch.randn(25, model.n_latent, 1, 1)\n",
    "    noises = noises.to(device)\n",
    "    samples = model.decode(noises)\n",
    "    \n",
    "    samples = (samples + 1) / 2\n",
    "    sample_grid = make_grid(samples, nrow=5, padding=20).cpu()\n",
    "    \n",
    "    plt.imshow(sample_grid.permute(1, 2, 0))  # easy way to swapaxes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the model\n",
    "\n",
    "!! checkpoints seems like the better way to do this !!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "path = save_path / 'full_model.p'\n",
    "path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.save(model.cpu(), path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model = model.to(device)\n",
    "len(test_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def testVAE2D(test_dl):\n",
    "    abnormal_loss_tracker = AvgTracker()\n",
    "    normal_loss_tracker = AvgTracker()\n",
    "\n",
    "    model.eval()\n",
    "    for i, (X, y) in tqdm(enumerate(test_dl)):\n",
    "\n",
    "        X = X.to(device)\n",
    "        X_hat, mu, logvar = model(X)\n",
    "        loss, loss_desc = criterion(X_hat, X, mu, logvar)\n",
    "\n",
    "        # Normal\n",
    "        if target.item() == 1:\n",
    "           normal_loss_tracker.update(loss.item())\n",
    "        # Abnormal\n",
    "        else:\n",
    "           abnormal_loss_tracker.update(loss.item())\n",
    "\n",
    "    return normal_loss_tracker.avg, abnormal_loss_tracker.avg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "Measure a difference score using the model and use it for outlier detection\n",
    "\"\"\"\n",
    "\n",
    "result_path = save_path / 'result.csv'\n",
    "\n",
    "############################# ANOMALY SCORE DEF ##########################\n",
    "def score(model, img, L=5):\n",
    "    \"\"\"\n",
    "    The vae score for a single image, which is basically the loss\n",
    "    input: image: [1, 3, 256, 256]\n",
    "    output: (loss, KL, gen_err)\n",
    "    \"\"\"\n",
    "    image_batch = image.expand(L,\n",
    "                               image.size(1),\n",
    "                               image.size(2),\n",
    "                               image.size(3))\n",
    "    reconst_batch, mu, logvar = vae.forward(image_batch)\n",
    "    vae_loss, loss_details = criterion(reconst_batch, image_batch, mu, logvar)\n",
    "    return vae_loss, loss_details['KL'], -loss_details['reconst_logp']\n",
    "\n",
    "def _log_mean_exp(x, dim):\n",
    "    \"\"\"\n",
    "    A numerical stable version of log(mean(exp(x)))\n",
    "    :param x: The input\n",
    "    :param dim: The dimension along which to take mean with\n",
    "    \"\"\"\n",
    "    # m [dim1, 1]\n",
    "    m, _ = torch.max(x, dim=dim, keepdim=True)\n",
    "\n",
    "    # x0 [dm1, dim2]\n",
    "    x0 = x - m\n",
    "\n",
    "    # m [dim1]\n",
    "    m = m.squeeze(dim)\n",
    "\n",
    "    return m + torch.log(torch.mean(torch.exp(x0),\n",
    "                                    dim=dim))\n",
    "\n",
    "def get_iwae_score(vae, image, L=5):\n",
    "    \"\"\"\n",
    "    The vae score for a single image, which is basically the loss\n",
    "    :param image: [1, 3, 256, 256]\n",
    "    :return scocre: (iwae score, iwae KL, iwae reconst).\n",
    "    \"\"\"\n",
    "    # [L, 3, 256, 256]\n",
    "    image_batch = image.expand(L,\n",
    "                               image.size(1),\n",
    "                               image.size(2),\n",
    "                               image.size(3))\n",
    "\n",
    "    # [L, z_dim, 1, 1]\n",
    "    mu, logvar = vae.encode(image_batch)\n",
    "    eps = torch.randn_like(mu)\n",
    "    z = mu + eps * torch.exp(0.5 * logvar)\n",
    "    kl_weight = criterion.kl_weight\n",
    "    # [L, 3, 256, 256]\n",
    "    reconst = vae.decode(z)\n",
    "    # [L]\n",
    "    log_p_x_z = -torch.sum((reconst - image_batch).pow(2).reshape(L, -1),\n",
    "                          dim=1)\n",
    "\n",
    "    # [L]\n",
    "    log_p_z = -torch.sum(z.pow(2).reshape(L, -1), dim=1)\n",
    "\n",
    "    # [L]\n",
    "    log_q_z = -torch.sum(eps.pow(2).reshape(L, -1), dim=1)\n",
    "\n",
    "    iwae_score = -_log_mean_exp(log_p_x_z + (log_p_z - log_q_z)*kl_weight, dim=0)\n",
    "    iwae_KL_score = -_log_mean_exp(log_p_z - log_q_z, dim=0)\n",
    "    iwae_reconst_score = -_log_mean_exp(log_p_x_z, dim=0)\n",
    "\n",
    "    return iwae_score, iwae_KL_score, iwae_reconst_score\n",
    "\n",
    "############################# END OF ANOMALY SCORE ###########################\n",
    "\n",
    "# Define the number of samples of each score\n",
    "def compute_all_scores(vae, image):\n",
    "    \"\"\"\n",
    "    Given an image compute all anomaly score\n",
    "    return (reconst_score, vae_score, iwae_score)\n",
    "    \"\"\"\n",
    "    vae_loss, KL, reconst_err = get_vae_score(vae, image=image, L=15)\n",
    "    iwae_loss, iwae_KL, iwae_reconst = get_iwae_score(vae, image, L=15)\n",
    "    result = {'reconst_score': reconst_err.item(),\n",
    "              'KL_score': KL.item(),\n",
    "              'vae_score': vae_loss.item(),\n",
    "              'iwae_score': iwae_loss.item(),\n",
    "              'iwae_KL_score': iwae_KL.item(),\n",
    "              'iwae_reconst_score': iwae_reconst.item()}\n",
    "    return result\n",
    "\n",
    "\n",
    "# MAIN LOOP\n",
    "score_names = ['reconst_score', 'KL_score', 'vae_score',\n",
    "               'iwae_reconst_score', 'iwae_KL_score', 'iwae_score']\n",
    "classes = test_loader.dataset.classes\n",
    "scores = {(score_name, cls): [] for (score_name, cls) in product(score_names,\n",
    "                                                                 classes)}\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for idx, (image, target) in tqdm(enumerate(test_loader)):\n",
    "        cls = classes[target.item()]\n",
    "        if args.cuda:\n",
    "            image = image.cuda()\n",
    "\n",
    "        score = compute_all_scores(vae=model, image=image)\n",
    "        for name in score_names:\n",
    "            scores[(name, cls)].append(score[name])\n",
    "\n",
    "# display the mean of scores\n",
    "means = np.zeros([len(score_names), len(classes)])\n",
    "for (name, cls) in product(score_names, classes):\n",
    "    means[score_names.index(name), classes.index(cls)] = sum(scores[(name, cls)]) / len(scores[(name, cls)])\n",
    "df_mean = pd.DataFrame(means, index=score_names, columns=classes)\n",
    "print(\"###################### MEANS #####################\")\n",
    "print(df_mean)\n",
    "\n",
    "\n",
    "classes.remove('NV')\n",
    "auc_result = np.zeros([len(score_names), len(classes) + 1])\n",
    "# get auc roc for each class\n",
    "for (name, cls) in product(score_names, classes):\n",
    "    normal_scores = scores[(name, 'NV')]\n",
    "    abnormal_scores = scores[(name, cls)]\n",
    "    y_true = [0]*len(normal_scores) + [1]*len(abnormal_scores)\n",
    "    y_score = normal_scores + abnormal_scores\n",
    "    auc_result[score_names.index(name), classes.index(cls)] = roc_auc_score(y_true, y_score)\n",
    "\n",
    "# add auc roc against all diseases\n",
    "for name in score_names:\n",
    "    normal_scores = scores[(name, 'NV')]\n",
    "    abnormal_scores = np.concatenate([scores[(name, cls)]for cls in classes]).tolist()\n",
    "    y_true = [0]*len(normal_scores) + [1]*len(abnormal_scores)\n",
    "    y_score = normal_scores + abnormal_scores\n",
    "    auc_result[score_names.index(name), -1] = roc_auc_score(y_true, y_score)\n",
    "\n",
    "df = pd.DataFrame(auc_result, index=score_names, columns=classes + ['ALL'])\n",
    "# display\n",
    "print(\"###################### AUC ROC #####################\")\n",
    "print(df)\n",
    "print(\"####################################################\")\n",
    "df.to_csv(args.out_csv)\n",
    "\n",
    "# fit a gamma distribution\n",
    "_, val_loader = load_vae_train_datasets(args.image_size, args.data, 32)\n",
    "model.eval()\n",
    "all_reconst_err = []\n",
    "num_val = len(val_loader.dataset)\n",
    "with torch.no_grad():\n",
    "    for img, _ in tqdm(val_loader):\n",
    "        if args.cuda:\n",
    "            img = img.cuda()\n",
    "\n",
    "        # compute output\n",
    "        recon_batch, mu, logvar = model(img)\n",
    "        loss, loss_details = criterion.forward_without_reduce(recon_batch, img, mu, logvar)\n",
    "        reconst_err = -loss_details['reconst_logp']\n",
    "        all_reconst_err += reconst_err.tolist()\n",
    "\n",
    "fit_alpha, fit_loc, fit_beta=stats.gamma.fit(all_reconst_err)\n",
    "\n",
    "# using gamma for outlier detection\n",
    "# get auc roc for each class\n",
    "LARGE_NUMBER = 1e30\n",
    "\n",
    "def get_gamma_score(scores):\n",
    "    result = -stats.gamma.logpdf(scores, fit_alpha, fit_loc, fit_beta)\n",
    "    # replace inf in result with largest number\n",
    "    result[result == np.inf] = LARGE_NUMBER\n",
    "    return result\n",
    "\n",
    "auc_gamma_result = np.zeros([1, len(classes)+1])\n",
    "name = 'reconst_score'\n",
    "for cls in classes:\n",
    "    normal_scores = get_gamma_score(scores[(name, 'NV')]).tolist()\n",
    "    abnormal_scores = get_gamma_score(scores[(name, cls)]).tolist()\n",
    "    y_true = [0]*len(normal_scores) + [1]*len(abnormal_scores)\n",
    "    y_score = normal_scores + abnormal_scores\n",
    "    auc_gamma_result[0, classes.index(cls)] = roc_auc_score(y_true, y_score)\n",
    "\n",
    "# for all class\n",
    "normal_scores = get_gamma_score(scores[(name, 'NV')]).tolist()\n",
    "abnormal_scores = np.concatenate([get_gamma_score(scores[(name, cls)]) for cls in classes]).tolist()\n",
    "y_true = [0]*len(normal_scores) + [1]*len(abnormal_scores)\n",
    "y_score = normal_scores + abnormal_scores\n",
    "auc_gamma_result[0, -1] = roc_auc_score(y_true, y_score)\n",
    "df = pd.DataFrame(auc_gamma_result, index=['gamma score'], columns=classes + ['ALL'])\n",
    "\n",
    "# display\n",
    "print(\"###################### AUC ROC GAMMA #####################\")\n",
    "print(df)\n",
    "print(\"##########################################################\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
