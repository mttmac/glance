{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, math, time\n",
    "from pathlib import Path\n",
    "from datetime import date\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms, datasets\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.debugger import set_trace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define a VAE Model\n",
    "Initially designed for 2D input images.\n",
    "Based on this paper: https://arxiv.org/abs/1807.01349"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth = 64      # initial depth to convolve channels into\n",
    "n_channels = 3  # number of channels (RGB)\n",
    "filt_size = 4   # convolution filter size\n",
    "stride = 2      # stride for conv\n",
    "pad = 1         # padding added for conv\n",
    "\n",
    "class VAE2D(nn.Module):\n",
    "    def __init__(self, img_size, n_latent=300):\n",
    "        \n",
    "        # Model setup\n",
    "        #############\n",
    "        super(VAE2D, self).__init__()\n",
    "        self.n_latent = n_latent\n",
    "        n = math.log2(img_size)\n",
    "        assert n == round(n), 'Image size must be a power of 2'  # restrict image input sizes permitted\n",
    "        assert n >= 3, 'Image size must be at least 8'           # low dimensional data won't work well\n",
    "        n = int(n)\n",
    "\n",
    "        # Encoder - first half of VAE\n",
    "        #############################\n",
    "        self.encoder = nn.Sequential()  \n",
    "        # input: n_channels x img_size x img_size\n",
    "        # ouput: depth x conv_img_size^2\n",
    "        # conv_img_size = (img_size - filt_size + 2 * pad) / stride + 1\n",
    "        self.encoder.add_module('input-conv', nn.Conv2d(n_channels, depth, filt_size, stride, pad,\n",
    "                                                        bias=True))\n",
    "        self.encoder.add_module('input-relu', nn.ReLU(inplace=True))\n",
    "        \n",
    "        # Add conv layer for each power of 2 over 3 (min size)\n",
    "        # Pyramid strategy with batch normalization added\n",
    "        for i in range(n - 3):\n",
    "            # input: depth x conv_img_size^2\n",
    "            # output: o_depth x conv_img_size^2\n",
    "            # i_depth = o_depth of previous layer\n",
    "            i_depth = depth * 2 ** i\n",
    "            o_depth = depth * 2 ** (i + 1)\n",
    "            self.encoder.add_module(f'pyramid_{i_depth}-{o_depth}_conv',\n",
    "                                    nn.Conv2d(i_depth, o_depth, filt_size, stride, pad, bias=True))\n",
    "            self.encoder.add_module(f'pyramid_{o_depth}_batchnorm',\n",
    "                                    nn.BatchNorm2d(o_depth))\n",
    "            self.encoder.add_module(f'pyramid_{o_depth}_relu',\n",
    "                                    nn.ReLU(inplace=True))\n",
    "        \n",
    "        # Latent representation\n",
    "        #######################\n",
    "        # Convolve the encoded image into the latent space, once for mu and once for logvar\n",
    "        max_depth = depth * 2 ** (n - 3)\n",
    "        self.conv_mu = nn.Conv2d(max_depth, n_latent, filt_size)      # return the mean of the latent space \n",
    "        self.conv_logvar = nn.Conv2d(max_depth, n_latent, filt_size)  # return the log variance of the same\n",
    "        \n",
    "        \n",
    "        # Decoder - second half of VAE\n",
    "        ##############################\n",
    "        self.decoder = nn.Sequential()\n",
    "        # input: max_depth x conv_img_size^2 (8 x 8)  TODO double check sizes\n",
    "        # output: n_latent x conv_img_size^2 (8 x 8)\n",
    "        # default stride=1, pad=0 for this layer\n",
    "        self.decoder.add_module('input-conv', nn.ConvTranspose2d(n_latent, max_depth, filt_size, bias=True))\n",
    "        self.decoder.add_module('input-batchnorm', nn.BatchNorm2d(max_depth))\n",
    "        self.decoder.add_module('input-relu', nn.ReLU(inplace=True))\n",
    "    \n",
    "        # Reverse the convolution pyramids used in the encoder\n",
    "        for i in range(n - 3, 0, -1):\n",
    "            i_depth = depth * 2 ** i\n",
    "            o_depth = depth * 2 ** (i - 1)\n",
    "            self.decoder.add_module(f'pyramid_{i_depth}-{o_depth}_conv',\n",
    "                                    nn.ConvTranspose2d(i_depth, o_depth, filt_size, stride, pad, bias=True))\n",
    "            self.decoder.add_module(f'pyramid_{o_depth}_batchnorm',\n",
    "                                    nn.BatchNorm2d(o_depth))\n",
    "            self.decoder.add_module(f'pyramid_{o_depth}_relu', nn.ReLU(inplace=True))\n",
    "        \n",
    "        # Final transposed convolution to return to img_size\n",
    "        # Final activation is tanh instead of relu to allow negative pixel output\n",
    "        self.decoder.add_module('output-conv', nn.ConvTranspose2d(depth, n_channels,\n",
    "                                                                  filt_size, stride, pad, bias=True))\n",
    "        self.decoder.add_module('output-tanh', nn.Tanh())\n",
    "\n",
    "        # Model weights init\n",
    "        ####################\n",
    "        # Randomly initialize the model weights using kaiming method\n",
    "        # Reference: \"Delving deep into rectifiers: Surpassing human-level\n",
    "        # performance on ImageNet classification\" - He, K. et al. (2015)\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "\n",
    "    def encode(self, imgs):\n",
    "        \"\"\"\n",
    "        Encode the images into latent space vectors (mean and log variance representation)\n",
    "        input:  imgs   [batch_size, 3, 256, 256]\n",
    "        output: mu     [batch_size, n_latent, 1, 1]\n",
    "                logvar [batch_size, n_latent, 1, 1]\n",
    "        \"\"\"\n",
    "        output = self.encoder(imgs)\n",
    "        output = output.squeeze(-1).squeeze(-1)\n",
    "        return [self.conv_mu(output), self.conv_logvar(output)]\n",
    "\n",
    "    def generate(self, mu, logvar):\n",
    "        \"\"\"\n",
    "        Generates a random latent vector using the trained mean and log variance representation\n",
    "        input:  mu     [batch_size, n_latent, 1, 1]\n",
    "                logvar [batch_size, n_latent, 1, 1]\n",
    "        output: gen    [batch_size, n_latent, 1, 1]\n",
    "        \"\"\"\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        gen = torch.randn_like(std)\n",
    "        return gen.mul(std).add_(mu)\n",
    "\n",
    "    def decode(self, gen):\n",
    "        \"\"\"\n",
    "        Restores an image representation from the generated latent vector\n",
    "        input:  gen      [batch_size, n_latent, 1, 1]\n",
    "        output: gen_imgs [batch_size, 3, 256, 256]\n",
    "        \"\"\"\n",
    "        return self.decoder(gen)\n",
    "\n",
    "    def forward(self, imgs):\n",
    "        \"\"\"\n",
    "        Generates reconstituted images from input images based on learned representation\n",
    "        input: imgs     [batch_size, 3, 256, 256]\n",
    "        ouput: gen_imgs [batch_size, 3, 256, 256]\n",
    "               mu       [batch_size, n_latent]\n",
    "               logvar   [batch_size, n_latent]\n",
    "        \"\"\"\n",
    "        mu, logvar = self.encode(imgs)\n",
    "        gen = self.generate(mu, logvar)\n",
    "        for tensor in (mu, logvar):\n",
    "            tensor = tensor.squeeze(-1).squeeze(-1)\n",
    "        return self.decode(gen), mu, logvar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VAE2D(256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VAE2D(\n",
       "  (encoder): Sequential(\n",
       "    (input-conv): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (input-relu): ReLU(inplace)\n",
       "    (pyramid_64-128_conv): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (pyramid_128_batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (pyramid_128_relu): ReLU(inplace)\n",
       "    (pyramid_128-256_conv): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (pyramid_256_batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (pyramid_256_relu): ReLU(inplace)\n",
       "    (pyramid_256-512_conv): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (pyramid_512_batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (pyramid_512_relu): ReLU(inplace)\n",
       "    (pyramid_512-1024_conv): Conv2d(512, 1024, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (pyramid_1024_batchnorm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (pyramid_1024_relu): ReLU(inplace)\n",
       "    (pyramid_1024-2048_conv): Conv2d(1024, 2048, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (pyramid_2048_batchnorm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (pyramid_2048_relu): ReLU(inplace)\n",
       "  )\n",
       "  (conv_mu): Conv2d(2048, 300, kernel_size=(4, 4), stride=(1, 1))\n",
       "  (conv_logvar): Conv2d(2048, 300, kernel_size=(4, 4), stride=(1, 1))\n",
       "  (decoder): Sequential(\n",
       "    (input-conv): ConvTranspose2d(300, 2048, kernel_size=(4, 4), stride=(1, 1))\n",
       "    (input-batchnorm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (input-relu): ReLU(inplace)\n",
       "    (pyramid_2048-1024_conv): ConvTranspose2d(2048, 1024, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (pyramid_1024_batchnorm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (pyramid_1024_relu): ReLU(inplace)\n",
       "    (pyramid_1024-512_conv): ConvTranspose2d(1024, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (pyramid_512_batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (pyramid_512_relu): ReLU(inplace)\n",
       "    (pyramid_512-256_conv): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (pyramid_256_batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (pyramid_256_relu): ReLU(inplace)\n",
       "    (pyramid_256-128_conv): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (pyramid_128_batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (pyramid_128_relu): ReLU(inplace)\n",
       "    (pyramid_128-64_conv): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (pyramid_64_batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (pyramid_64_relu): ReLU(inplace)\n",
       "    (output-conv): ConvTranspose2d(64, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (output-tanh): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define a loss function\n",
    "Must be suitable for anomaly detection by recreation similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE2DLoss(nn.Module):\n",
    "\n",
    "    def __init__(self, kl_weight=1):\n",
    "        super(VAE2DLoss, self).__init__()\n",
    "        self.kl_weight = kl_weight\n",
    "\n",
    "    def forward(self, gen_imgs, imgs, mu, logvar):\n",
    "        \"\"\"\n",
    "        input:  gen_imgs [batch_size, n_channels, img_size, img_size]\n",
    "                imgs     [batch_size, n_channels, img_size, img_size]\n",
    "                mu       [batch_size, n_latent]\n",
    "                logvar   [batch_size, n_latent]\n",
    "        output: loss      scalar (-ELBO)\n",
    "                loss_desc {'KL': KL, 'gen_logp': gen_err}\n",
    "        \"\"\"\n",
    "        batch_size = imgs.shape[0]\n",
    "        gen_err = (imgs - gen_imgs).pow(2).reshape(batch_size, -1)\n",
    "        gen_err = 0.5 * torch.sum(gen_err, dim=-1)\n",
    "        gen_err = torch.mean(gen_err)\n",
    "\n",
    "        # KL(q || p) = -log_sigma + sigma^2/2 + mu^2/2 - 1/2\n",
    "        KL = (-logvar + logvar.exp() + mu.pow(2) - 1) * 0.5\n",
    "        KL = torch.sum(KL, dim=-1)\n",
    "        KL = torch.mean(KL)\n",
    "\n",
    "        loss = gen_err + self.kl_weight * KL\n",
    "        return loss, {'KL': KL, 'gen_logp': -gen_err}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_datasets(img_size, data_path):\n",
    "    \"\"\"\n",
    "    Load the image datasets from vae_train and vae_test\n",
    "    Transform to correct image size\n",
    "    \"\"\"\n",
    "    \n",
    "    train_path = data_path / 'vae_train/train/'\n",
    "    val_path = data_path / 'vae_train/val/'\n",
    "    test_path = data_path / 'vae_test/'\n",
    "    \n",
    "    norm_args = {'mean': [0.5] * n_channels,\n",
    "                 'std': [0.5] * n_channels}\n",
    "    jitter_args = {'brightness': 0.1,\n",
    "                   'contrast': 0.1,\n",
    "                   'saturation': 0.1}  # hue unchanged\n",
    "    \n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.Resize(img_size),\n",
    "        transforms.RandomCrop(img_size),          # vary horizontal position\n",
    "        transforms.RandomHorizontalFlip(p=0.25),  # vary photo orientation\n",
    "        transforms.RandomVerticalFlip(p=0.25),\n",
    "        transforms.ColorJitter(**jitter_args),    # vary photo lighting\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(**norm_args)])\n",
    "    \n",
    "    test_transform = transforms.Compose([\n",
    "        transforms.Resize(img_size),\n",
    "        transforms.CenterCrop(img_size),  # assume center is most important\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(**norm_args)])\n",
    "\n",
    "    train_ds = datasets.ImageFolder(train_path, train_transform)\n",
    "    val_ds = datasets.ImageFolder(val_path, test_transform)\n",
    "    test_ds = datasets.ImageFolder(test_path, test_transform)\n",
    "    \n",
    "    \n",
    "    loader_args = {'shuffle': True,\n",
    "                   'num_workers': 4}\n",
    "    train_dl = torch.utils.data.DataLoader(train_ds, batch_size=batch_size, **loader_args)\n",
    "    val_dl = torch.utils.data.DataLoader(val_ds, batch_size=batch_size, **loader_args)\n",
    "    test_dl = torch.utils.data.DataLoader(test_ds, batch_size=1, ** loader_args)\n",
    "    \n",
    "    return train_dl, val_dl, test_dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model/Data parameters\n",
    "desc = 'VAE for detecting anomalies in 2D images'\n",
    "data_path = Path('data/NV_outlier/')\n",
    "img_size = 128\n",
    "n_channels = 3\n",
    "\n",
    "# Training parameters\n",
    "epochs = 40\n",
    "lr = 1e-4                # learning rate\n",
    "lr_decay = 0.1           # lr decay factor\n",
    "kl_weight = 0.01         # weighted factor of the KL term\n",
    "schedule = [10, 20, 30]  # decrease lr at these epochs\n",
    "batch_size = 32\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Checkpoints/Logging parameters\n",
    "save_path = Path(f\"models/{date.today().strftime('%y%m%d')}/\")\n",
    "load_path = None         # checkpoint to resume from (default None)\n",
    "log_freq = 10            # print status after this many batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl, val_dl, test_dl = load_datasets(img_size, data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 11 958\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dl), len(val_dl), len(test_dl))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model\n",
    "model = VAE2D(img_size)\n",
    "\n",
    "# Load optimizer and scheduler\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, schedule, lr_decay)\n",
    "\n",
    "# Load checkpoint if any\n",
    "if load_path is not None:\n",
    "    checkpoint = torch.load(load_path, map_location=device)\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "    print(\"Checkpoint loaded\")\n",
    "    print(f\"Validation loss: {checkpoint['val_loss']}\")\n",
    "    print(f\"Epoch: {checkpoint['epoch']}\")\n",
    "\n",
    "# Set loss criterion\n",
    "criterion = VAE2DLoss(kl_weight=kl_weight)\n",
    "\n",
    "# Move to GPU\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder models/190124 already exists\n"
     ]
    }
   ],
   "source": [
    "# Make save directory\n",
    "if save_path.is_dir():\n",
    "    print(f\"Folder {save_path} already exists\")\n",
    "else:\n",
    "    os.mkdir(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - add in logging to Visdom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convenience classes\n",
    "class StopWatch(object):\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "        \n",
    "    def reset(self):\n",
    "        self.start = time.time()\n",
    "        self.lap_start = time.time()\n",
    "        self.elapsed = []\n",
    "    \n",
    "    def lap(self):\n",
    "        self.elapsed.append(time.time() - self.lap_start)\n",
    "    \n",
    "class AvgTracker(object):\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.sum = 0\n",
    "        self.avg = 0\n",
    "        self.cnt = 0\n",
    "\n",
    "    def update(self, val):\n",
    "        self.val = val\n",
    "        self.sum += val\n",
    "        self.cnt += 1\n",
    "        self.avg = self.sum / self.cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainVAE2D(dl):\n",
    "    loss_tracker = AvgTracker()\n",
    "    kl_tracker = AvgTracker()\n",
    "    logp_tracker = AvgTracker()\n",
    "    timer = StopWatch()\n",
    "    \n",
    "    for i, (X, _) in tqdm(enumerate(dl)):\n",
    "        \n",
    "        X = X.to(device)\n",
    "        timer.lap()  # load time\n",
    "        \n",
    "        # Generate images and compute loss\n",
    "        X_hat, mu, logvar = model(X)\n",
    "        loss, loss_desc = criterion(X_hat, X, mu, logvar)\n",
    "        timer.lap()  # gen time\n",
    "        \n",
    "        loss_tracker.update(loss.item())\n",
    "        kl_tracker.update(loss_desc['KL'].item())\n",
    "        logp_tracker.update(loss_desc['gen_logp'].item())\n",
    "        \n",
    "        if model.training:\n",
    "            # Update weights\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            timer.lap()  # backprop time\n",
    "        \n",
    "        if i % log_freq == 0:\n",
    "            # Print progress\n",
    "            print(f'Epoch: {epoch + 1} ({i}/{len(dl)})')\n",
    "            print(f'\\tData load time: {timer.elapsed[0]:.3f} sec')\n",
    "            print(f'\\tGeneration time: {timer.elapsed[1]:.3f} sec')\n",
    "            if model.training:\n",
    "                print(f'\\tBackprop time: {timer.elapsed[2]:.3f} sec')\n",
    "            print(f'\\tLog probability: {logp_tracker.val:.4f} '\n",
    "                  f'(avg {logp_tracker.avg:.4f})')\n",
    "            print(f'\\tKL: {kl_tracker.val:.4f} (avg {kl_tracker.avg:.4f})')\n",
    "            print(f'\\tLoss: {loss_tracker.val:.4f} (avg {loss_tracker.avg:.4f})')\n",
    "\n",
    "    return loss_tracker.avg, kl_tracker.avg, logp_tracker.avg\n",
    "\n",
    "\n",
    "def testVAE2D(test_dl):\n",
    "    abnormal_loss_tracker = AvgTracker()\n",
    "    normal_loss_tracker = AvgTracker()\n",
    "\n",
    "    model.eval()\n",
    "    for i, (X, y) in tqdm(enumerate(test_dl)):\n",
    "\n",
    "        X = X.to(device)\n",
    "        X_hat, mu, logvar = model(X)\n",
    "        loss, loss_desc = criterion(X_hat, X, mu, logvar)\n",
    "\n",
    "        # Normal\n",
    "        if target.item() == 1:\n",
    "           normal_loss_tracker.update(loss.item())\n",
    "        # Abnormal\n",
    "        else:\n",
    "           abnormal_loss_tracker.update(loss.item())\n",
    "\n",
    "    return normal_loss_tracker.avg, abnormal_loss_tracker.avg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "1it [00:00,  1.06it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 (0/200)\n",
      "\tData load time: 0.827 sec\n",
      "\tGeneration time: 0.834 sec\n",
      "\tBackprop time: 1.042 sec\n",
      "\tLog probability: -617.5640 (avg -617.5640)\n",
      "\tKL: 9.3432 (avg 9.3432)\n",
      "\tLoss: 617.6575 (avg 617.6575)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "2it [00:01,  1.26it/s]\u001b[A\u001b[A\n",
      "\n",
      "3it [00:01,  1.48it/s]\u001b[A\u001b[A\n",
      "\n",
      "4it [00:02,  1.68it/s]\u001b[A\u001b[A\n",
      "\n",
      "5it [00:02,  1.87it/s]\u001b[A\u001b[A\n",
      "\n",
      "6it [00:02,  2.02it/s]\u001b[A\u001b[A\n",
      "\n",
      "7it [00:03,  2.16it/s]\u001b[A\u001b[A\n",
      "\n",
      "8it [00:03,  2.26it/s]\u001b[A\u001b[A\n",
      "\n",
      "9it [00:04,  2.34it/s]\u001b[A\u001b[A\n",
      "\n",
      "10it [00:04,  2.41it/s]\u001b[A\u001b[A\n",
      "\n",
      "11it [00:04,  2.45it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 (10/200)\n",
      "\tData load time: 0.827 sec\n",
      "\tGeneration time: 0.834 sec\n",
      "\tBackprop time: 1.042 sec\n",
      "\tLog probability: -730.0179 (avg -686.9929)\n",
      "\tKL: 9.0999 (avg 9.6432)\n",
      "\tLoss: 730.1089 (avg 687.0893)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "12it [00:05,  2.47it/s]\u001b[A\u001b[A\n",
      "\n",
      "13it [00:05,  2.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "14it [00:06,  2.54it/s]\u001b[A\u001b[A\n",
      "\n",
      "15it [00:06,  2.54it/s]\u001b[A\u001b[A\n",
      "\n",
      "16it [00:06,  2.55it/s]\u001b[A\u001b[A\n",
      "\n",
      "17it [00:07,  2.56it/s]\u001b[A\u001b[A\n",
      "\n",
      "18it [00:07,  2.55it/s]\u001b[A\u001b[A\n",
      "\n",
      "19it [00:08,  2.56it/s]\u001b[A\u001b[A\n",
      "\n",
      "20it [00:08,  2.56it/s]\u001b[A\u001b[A\n",
      "\n",
      "21it [00:08,  2.55it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 (20/200)\n",
      "\tData load time: 0.827 sec\n",
      "\tGeneration time: 0.834 sec\n",
      "\tBackprop time: 1.042 sec\n",
      "\tLog probability: -640.7998 (avg -684.3577)\n",
      "\tKL: 8.8424 (avg 9.5287)\n",
      "\tLoss: 640.8882 (avg 684.4530)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "22it [00:09,  2.56it/s]\u001b[A\u001b[A\n",
      "\n",
      "23it [00:09,  2.57it/s]\u001b[A\u001b[A\n",
      "\n",
      "24it [00:10,  2.56it/s]\u001b[A\u001b[A\n",
      "\n",
      "25it [00:10,  2.57it/s]\u001b[A\u001b[A\n",
      "\n",
      "26it [00:10,  2.56it/s]\u001b[A\u001b[A\n",
      "\n",
      "27it [00:11,  2.56it/s]\u001b[A\u001b[A\n",
      "\n",
      "28it [00:11,  2.54it/s]\u001b[A\u001b[A\n",
      "\n",
      "29it [00:11,  2.55it/s]\u001b[A\u001b[A\n",
      "\n",
      "30it [00:12,  2.54it/s]\u001b[A\u001b[A\n",
      "\n",
      "31it [00:12,  2.55it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 (30/200)\n",
      "\tData load time: 0.827 sec\n",
      "\tGeneration time: 0.834 sec\n",
      "\tBackprop time: 1.042 sec\n",
      "\tLog probability: -493.6983 (avg -645.2374)\n",
      "\tKL: 8.8476 (avg 9.3283)\n",
      "\tLoss: 493.7868 (avg 645.3307)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "32it [00:13,  2.55it/s]\u001b[A\u001b[A\n",
      "\n",
      "33it [00:13,  2.55it/s]\u001b[A\u001b[A\n",
      "\n",
      "34it [00:13,  2.56it/s]\u001b[A\u001b[A\n",
      "\n",
      "35it [00:14,  2.57it/s]\u001b[A\u001b[A\n",
      "\n",
      "36it [00:14,  2.56it/s]\u001b[A\u001b[A\n",
      "\n",
      "37it [00:15,  2.55it/s]\u001b[A\u001b[A\n",
      "\n",
      "38it [00:15,  2.57it/s]\u001b[A\u001b[A\n",
      "\n",
      "39it [00:15,  2.54it/s]\u001b[A\u001b[A\n",
      "\n",
      "40it [00:16,  2.55it/s]\u001b[A\u001b[A\n",
      "\n",
      "41it [00:16,  2.55it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 (40/200)\n",
      "\tData load time: 0.827 sec\n",
      "\tGeneration time: 0.834 sec\n",
      "\tBackprop time: 1.042 sec\n",
      "\tLog probability: -739.5546 (avg -627.5278)\n",
      "\tKL: 8.6113 (avg 9.1869)\n",
      "\tLoss: 739.6407 (avg 627.6197)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "42it [00:17,  2.54it/s]\u001b[A\u001b[A\n",
      "\n",
      "43it [00:17,  2.56it/s]\u001b[A\u001b[A\n",
      "\n",
      "44it [00:17,  2.56it/s]\u001b[A\u001b[A\n",
      "\n",
      "45it [00:18,  2.55it/s]\u001b[A\u001b[A\n",
      "\n",
      "46it [00:18,  2.56it/s]\u001b[A\u001b[A\n",
      "\n",
      "47it [00:19,  2.56it/s]\u001b[A\u001b[A\n",
      "\n",
      "48it [00:19,  2.55it/s]\u001b[A\u001b[A\n",
      "\n",
      "49it [00:19,  2.55it/s]\u001b[A\u001b[A\n",
      "\n",
      "50it [00:20,  2.55it/s]\u001b[A\u001b[A\n",
      "\n",
      "51it [00:20,  2.54it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 (50/200)\n",
      "\tData load time: 0.827 sec\n",
      "\tGeneration time: 0.834 sec\n",
      "\tBackprop time: 1.042 sec\n",
      "\tLog probability: -464.6272 (avg -612.7417)\n",
      "\tKL: 8.5366 (avg 9.3631)\n",
      "\tLoss: 464.7125 (avg 612.8354)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "52it [00:20,  2.56it/s]\u001b[A\u001b[A\n",
      "\n",
      "53it [00:21,  2.56it/s]\u001b[A\u001b[A\n",
      "\n",
      "54it [00:21,  2.56it/s]\u001b[A\u001b[A\n",
      "\n",
      "55it [00:22,  2.57it/s]\u001b[A\u001b[A\n",
      "\n",
      "56it [00:22,  2.57it/s]\u001b[A\u001b[A\n",
      "\n",
      "57it [00:22,  2.56it/s]\u001b[A\u001b[A\n",
      "\n",
      "58it [00:23,  2.56it/s]\u001b[A\u001b[A\n",
      "\n",
      "59it [00:23,  2.55it/s]\u001b[A\u001b[A\n",
      "\n",
      "60it [00:24,  2.55it/s]\u001b[A\u001b[A\n",
      "\n",
      "61it [00:24,  2.55it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 (60/200)\n",
      "\tData load time: 0.827 sec\n",
      "\tGeneration time: 0.834 sec\n",
      "\tBackprop time: 1.042 sec\n",
      "\tLog probability: -514.1101 (avg -600.4136)\n",
      "\tKL: 8.6883 (avg 9.3336)\n",
      "\tLoss: 514.1970 (avg 600.5070)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "62it [00:24,  2.55it/s]\u001b[A\u001b[A\n",
      "\n",
      "63it [00:25,  2.55it/s]\u001b[A\u001b[A\n",
      "\n",
      "64it [00:25,  2.56it/s]\u001b[A\u001b[A\n",
      "\n",
      "65it [00:26,  2.56it/s]\u001b[A\u001b[A\n",
      "\n",
      "66it [00:26,  2.56it/s]\u001b[A\u001b[A\n",
      "\n",
      "67it [00:26,  2.55it/s]\u001b[A\u001b[A\n",
      "\n",
      "68it [00:27,  2.55it/s]\u001b[A\u001b[A\n",
      "\n",
      "69it [00:27,  2.53it/s]\u001b[A\u001b[A\n",
      "\n",
      "70it [00:28,  2.54it/s]\u001b[A\u001b[A\n",
      "\n",
      "71it [00:28,  2.54it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 (70/200)\n",
      "\tData load time: 0.827 sec\n",
      "\tGeneration time: 0.834 sec\n",
      "\tBackprop time: 1.042 sec\n",
      "\tLog probability: -533.4414 (avg -589.7215)\n",
      "\tKL: 8.8672 (avg 9.3440)\n",
      "\tLoss: 533.5301 (avg 589.8149)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "72it [00:28,  2.53it/s]\u001b[A\u001b[A\n",
      "\n",
      "73it [00:29,  2.54it/s]\u001b[A\u001b[A\n",
      "\n",
      "74it [00:29,  2.53it/s]\u001b[A\u001b[A\n",
      "\n",
      "75it [00:30,  2.54it/s]\u001b[A\u001b[A\n",
      "\n",
      "76it [00:30,  2.56it/s]\u001b[A\u001b[A\n",
      "\n",
      "77it [00:30,  2.55it/s]\u001b[A\u001b[A\n",
      "\n",
      "78it [00:31,  2.55it/s]\u001b[A\u001b[A\n",
      "\n",
      "79it [00:31,  2.55it/s]\u001b[A\u001b[A\n",
      "\n",
      "80it [00:31,  2.55it/s]\u001b[A\u001b[A\n",
      "\n",
      "81it [00:32,  2.54it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 (80/200)\n",
      "\tData load time: 0.827 sec\n",
      "\tGeneration time: 0.834 sec\n",
      "\tBackprop time: 1.042 sec\n",
      "\tLog probability: -447.1297 (avg -578.4395)\n",
      "\tKL: 8.7112 (avg 9.2855)\n",
      "\tLoss: 447.2168 (avg 578.5323)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "82it [00:32,  2.55it/s]\u001b[A\u001b[A\n",
      "\n",
      "83it [00:33,  2.53it/s]\u001b[A\u001b[A\n",
      "\n",
      "84it [00:33,  2.54it/s]\u001b[A\u001b[A\n",
      "\n",
      "85it [00:33,  2.53it/s]\u001b[A\u001b[A\n",
      "\n",
      "86it [00:34,  2.53it/s]\u001b[A\u001b[A\n",
      "\n",
      "87it [00:34,  2.54it/s]\u001b[A\u001b[A\n",
      "\n",
      "88it [00:35,  2.55it/s]\u001b[A\u001b[A\n",
      "\n",
      "89it [00:35,  2.55it/s]\u001b[A\u001b[A\n",
      "\n",
      "90it [00:35,  2.56it/s]\u001b[A\u001b[A\n",
      "\n",
      "91it [00:36,  2.56it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 (90/200)\n",
      "\tData load time: 0.827 sec\n",
      "\tGeneration time: 0.834 sec\n",
      "\tBackprop time: 1.042 sec\n",
      "\tLog probability: -538.3646 (avg -564.0941)\n",
      "\tKL: 9.1508 (avg 9.3588)\n",
      "\tLoss: 538.4561 (avg 564.1877)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "92it [00:36,  2.55it/s]\u001b[A\u001b[A\n",
      "\n",
      "93it [00:37,  2.55it/s]\u001b[A\u001b[A\n",
      "\n",
      "94it [00:37,  2.55it/s]\u001b[A\u001b[A\n",
      "\n",
      "95it [00:37,  2.53it/s]\u001b[A\u001b[A\n",
      "\n",
      "96it [00:38,  2.55it/s]\u001b[A\u001b[A\n",
      "\n",
      "97it [00:38,  2.54it/s]\u001b[A\u001b[A\n",
      "\n",
      "98it [00:39,  2.54it/s]\u001b[A\u001b[A\n",
      "\n",
      "99it [00:39,  2.55it/s]\u001b[A\u001b[A\n",
      "\n",
      "100it [00:39,  2.55it/s]\u001b[A\u001b[A\n",
      "\n",
      "101it [00:40,  2.56it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 (100/200)\n",
      "\tData load time: 0.827 sec\n",
      "\tGeneration time: 0.834 sec\n",
      "\tBackprop time: 1.042 sec\n",
      "\tLog probability: -509.7361 (avg -551.2314)\n",
      "\tKL: 8.2835 (avg 9.2989)\n",
      "\tLoss: 509.8190 (avg 551.3244)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "102it [00:40,  2.55it/s]\u001b[A\u001b[A\n",
      "\n",
      "103it [00:41,  2.54it/s]\u001b[A\u001b[A\n",
      "\n",
      "104it [00:41,  2.53it/s]\u001b[A\u001b[A\n",
      "\n",
      "105it [00:41,  2.54it/s]\u001b[A\u001b[A\n",
      "\n",
      "106it [00:42,  2.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "107it [00:42,  2.53it/s]\u001b[A\u001b[A\n",
      "\n",
      "108it [00:42,  2.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "109it [00:43,  2.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "110it [00:43,  2.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "111it [00:44,  2.49it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 (110/200)\n",
      "\tData load time: 0.827 sec\n",
      "\tGeneration time: 0.834 sec\n",
      "\tBackprop time: 1.042 sec\n",
      "\tLog probability: -437.3727 (avg -541.0066)\n",
      "\tKL: 8.6892 (avg 9.2484)\n",
      "\tLoss: 437.4595 (avg 541.0991)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "112it [00:44,  2.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "113it [00:44,  2.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "114it [00:45,  2.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "115it [00:45,  2.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "116it [00:46,  2.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "117it [00:46,  2.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "118it [00:47,  2.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "119it [00:47,  2.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "120it [00:47,  2.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "121it [00:48,  2.50it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 (120/200)\n",
      "\tData load time: 0.827 sec\n",
      "\tGeneration time: 0.834 sec\n",
      "\tBackprop time: 1.042 sec\n",
      "\tLog probability: -342.2521 (avg -532.2367)\n",
      "\tKL: 8.3820 (avg 9.1901)\n",
      "\tLoss: 342.3359 (avg 532.3286)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "122it [00:48,  2.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "123it [00:49,  2.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "124it [00:49,  2.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "125it [00:49,  2.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "126it [00:50,  2.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "127it [00:50,  2.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "128it [00:50,  2.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "129it [00:51,  2.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "130it [00:51,  2.53it/s]\u001b[A\u001b[A\n",
      "\n",
      "131it [00:52,  2.55it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 (130/200)\n",
      "\tData load time: 0.827 sec\n",
      "\tGeneration time: 0.834 sec\n",
      "\tBackprop time: 1.042 sec\n",
      "\tLog probability: -353.6423 (avg -522.4579)\n",
      "\tKL: 8.2746 (avg 9.1500)\n",
      "\tLoss: 353.7250 (avg 522.5494)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "132it [00:52,  2.54it/s]\u001b[A\u001b[A\n",
      "\n",
      "133it [00:52,  2.55it/s]\u001b[A\u001b[A\n",
      "\n",
      "134it [00:53,  2.54it/s]\u001b[A\u001b[A\n",
      "\n",
      "135it [00:53,  2.53it/s]\u001b[A\u001b[A\n",
      "\n",
      "136it [00:54,  2.54it/s]\u001b[A\u001b[A\n",
      "\n",
      "137it [00:54,  2.54it/s]\u001b[A\u001b[A\n",
      "\n",
      "138it [00:54,  2.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "139it [00:55,  2.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "140it [00:55,  2.53it/s]\u001b[A\u001b[A\n",
      "\n",
      "141it [00:56,  2.50it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 (140/200)\n",
      "\tData load time: 0.827 sec\n",
      "\tGeneration time: 0.834 sec\n",
      "\tBackprop time: 1.042 sec\n",
      "\tLog probability: -389.0826 (avg -515.1274)\n",
      "\tKL: 10.7975 (avg 9.1028)\n",
      "\tLoss: 389.1906 (avg 515.2185)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "142it [00:56,  2.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "143it [00:56,  2.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "144it [00:57,  2.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "145it [00:57,  2.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "146it [00:58,  2.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "147it [00:58,  2.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "148it [00:58,  2.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "149it [00:59,  2.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "150it [00:59,  2.53it/s]\u001b[A\u001b[A\n",
      "\n",
      "151it [01:00,  2.53it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 (150/200)\n",
      "\tData load time: 0.827 sec\n",
      "\tGeneration time: 0.834 sec\n",
      "\tBackprop time: 1.042 sec\n",
      "\tLog probability: -335.9324 (avg -507.1036)\n",
      "\tKL: 8.4285 (avg 9.0420)\n",
      "\tLoss: 336.0167 (avg 507.1940)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "152it [01:00,  2.54it/s]\u001b[A\u001b[A\n",
      "\n",
      "153it [01:00,  2.54it/s]\u001b[A\u001b[A\n",
      "\n",
      "154it [01:01,  2.54it/s]\u001b[A\u001b[A\n",
      "\n",
      "155it [01:01,  2.53it/s]\u001b[A\u001b[A\n",
      "\n",
      "156it [01:02,  2.53it/s]\u001b[A\u001b[A\n",
      "\n",
      "157it [01:02,  2.53it/s]\u001b[A\u001b[A\n",
      "\n",
      "158it [01:02,  2.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "159it [01:03,  2.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "160it [01:03,  2.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "161it [01:04,  2.52it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 (160/200)\n",
      "\tData load time: 0.827 sec\n",
      "\tGeneration time: 0.834 sec\n",
      "\tBackprop time: 1.042 sec\n",
      "\tLog probability: -503.8904 (avg -501.4184)\n",
      "\tKL: 7.9691 (avg 8.9870)\n",
      "\tLoss: 503.9701 (avg 501.5082)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "162it [01:04,  2.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "163it [01:04,  2.48it/s]\u001b[A\u001b[A\n",
      "\n",
      "164it [01:05,  2.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "165it [01:05,  2.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "166it [01:06,  2.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "167it [01:06,  2.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "168it [01:06,  2.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "169it [01:07,  2.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "170it [01:07,  2.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "171it [01:08,  2.50it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 (170/200)\n",
      "\tData load time: 0.827 sec\n",
      "\tGeneration time: 0.834 sec\n",
      "\tBackprop time: 1.042 sec\n",
      "\tLog probability: -379.4833 (avg -496.4038)\n",
      "\tKL: 7.7251 (avg 8.9329)\n",
      "\tLoss: 379.5605 (avg 496.4932)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "172it [01:08,  2.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "173it [01:08,  2.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "174it [01:09,  2.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "175it [01:09,  2.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "176it [01:10,  2.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "177it [01:10,  2.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "178it [01:10,  2.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "179it [01:11,  2.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "180it [01:11,  2.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "181it [01:12,  2.50it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 (180/200)\n",
      "\tData load time: 0.827 sec\n",
      "\tGeneration time: 0.834 sec\n",
      "\tBackprop time: 1.042 sec\n",
      "\tLog probability: -433.4616 (avg -490.4096)\n",
      "\tKL: 8.0388 (avg 8.8840)\n",
      "\tLoss: 433.5420 (avg 490.4985)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "182it [01:12,  2.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "183it [01:12,  2.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "184it [01:13,  2.53it/s]\u001b[A\u001b[A\n",
      "\n",
      "185it [01:13,  2.53it/s]\u001b[A\u001b[A\n",
      "\n",
      "186it [01:14,  2.54it/s]\u001b[A\u001b[A\n",
      "\n",
      "187it [01:14,  2.54it/s]\u001b[A\u001b[A\n",
      "\n",
      "188it [01:14,  2.54it/s]\u001b[A\u001b[A\n",
      "\n",
      "189it [01:15,  2.54it/s]\u001b[A\u001b[A\n",
      "\n",
      "190it [01:15,  2.53it/s]\u001b[A\u001b[A\n",
      "\n",
      "191it [01:16,  2.53it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 (190/200)\n",
      "\tData load time: 0.827 sec\n",
      "\tGeneration time: 0.834 sec\n",
      "\tBackprop time: 1.042 sec\n",
      "\tLog probability: -331.2886 (avg -486.4684)\n",
      "\tKL: 7.9677 (avg 8.8357)\n",
      "\tLoss: 331.3683 (avg 486.5568)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "192it [01:16,  2.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "193it [01:16,  2.53it/s]\u001b[A\u001b[A\n",
      "\n",
      "194it [01:17,  2.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "195it [01:17,  2.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "196it [01:18,  2.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "197it [01:18,  2.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "198it [01:18,  2.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "199it [01:19,  2.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "200it [01:19,  2.78it/s]\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "1it [00:00,  1.20it/s]\u001b[A\u001b[A\n",
      "\n",
      "2it [00:01,  1.57it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 (0/11)\n",
      "\tData load time: 0.773 sec\n",
      "\tGeneration time: 0.779 sec\n",
      "\tLog probability: -310.9161 (avg -310.9161)\n",
      "\tKL: 7.1471 (avg 7.1471)\n",
      "\tLoss: 310.9876 (avg 310.9876)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "3it [00:01,  2.03it/s]\u001b[A\u001b[A\n",
      "\n",
      "4it [00:01,  2.54it/s]\u001b[A\u001b[A\n",
      "\n",
      "5it [00:01,  2.80it/s]\u001b[A\u001b[A\n",
      "\n",
      "6it [00:01,  3.35it/s]\u001b[A\u001b[A\n",
      "\n",
      "7it [00:01,  3.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "8it [00:02,  4.39it/s]\u001b[A\u001b[A\n",
      "\n",
      "9it [00:02,  4.74it/s]\u001b[A\u001b[A\n",
      "\n",
      "10it [00:02,  5.16it/s]\u001b[A\u001b[A\n",
      "\n",
      "11it [00:02,  4.39it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 (10/11)\n",
      "\tData load time: 0.773 sec\n",
      "\tGeneration time: 0.779 sec\n",
      "\tLog probability: -299.8336 (avg -340.8479)\n",
      "\tKL: 7.1276 (avg 8.3076)\n",
      "\tLoss: 299.9049 (avg 340.9310)\n",
      "Lowest validation loss: inf\n",
      "Saving checkpoint..\n"
     ]
    },
    {
     "ename": "IsADirectoryError",
     "evalue": "[Errno 21] Is a directory: 'models/190124'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIsADirectoryError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-67-96716aa9edfc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m                      'optimizer': optimizer.state_dict()}\n\u001b[1;32m     22\u001b[0m         \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msave_path\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m'best_model.pth.tar'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol)\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m     \"\"\"\n\u001b[0;32m--> 218\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_with_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_with_file_like\u001b[0;34m(f, mode, body)\u001b[0m\n\u001b[1;32m    139\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpathlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0mnew_fd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIsADirectoryError\u001b[0m: [Errno 21] Is a directory: 'models/190124'"
     ]
    }
   ],
   "source": [
    "# Main loop\n",
    "best_loss = np.inf\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    model.train()\n",
    "    scheduler.step()\n",
    "    train_loss, train_kl, train_logp = trainVAE2D(train_dl)\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_loss, val_kl, val_logp = trainVAE2D(val_dl)\n",
    "\n",
    "    # Report training progress to user\n",
    "    print(f'Lowest validation loss: {best_loss:.4f}')\n",
    "    if val_loss < best_loss:\n",
    "        print('Saving checkpoint..')\n",
    "        best_loss = val_loss\n",
    "        save_dict = {'epoch': epoch + 1,\n",
    "                     'state_dict': model.state_dict(),\n",
    "                     'val_loss': val_loss,\n",
    "                     'optimizer': optimizer.state_dict()}\n",
    "        path = save_path / 'best_model.pth.tar'\n",
    "        torch.save(save_dict, save_path)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ADD VISUALIZATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # TODO include in epoch loop?\n",
    "    # TODO look into what the scheduler is for\n",
    "    # visualize reconst and free sample\n",
    "    print(\"Plotting example imgs...\")\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        val_iter = iter(val_dl)\n",
    "\n",
    "        # reconstruct 25 imgs\n",
    "        imgs = val_iter._get_batch()[1][0][:25]\n",
    "        if args.cuda:\n",
    "            imgs = imgs.cuda()\n",
    "        imgs_reconst, mu, logvar = model(imgs)\n",
    "\n",
    "        # sample 25 imgs\n",
    "        noises = torch.randn(25, model.nz, 1, 1)\n",
    "        if args.cuda:\n",
    "            noises = noises.cuda()\n",
    "        samples = model.decode(noises)\n",
    "\n",
    "        def write_image(tag, images):\n",
    "            \"\"\"\n",
    "            write the resulting imgs to tensorboard.\n",
    "            :param tag: The tag for tensorboard\n",
    "            :param images: the torch tensor with range (-1, 1). [9, 3, 256, 256]\n",
    "            \"\"\"\n",
    "            # make it from 0 to 255\n",
    "            images = (images + 1) / 2\n",
    "            grid = make_grid(images, nrow=5, padding=20)\n",
    "            writer.add_image(tag, grid.detach(), global_step=epoch + 1)\n",
    "\n",
    "        write_image(\"origin\", imgs)\n",
    "        write_image(\"reconst\", imgs_reconst)\n",
    "        write_image(\"samples\", samples)\n",
    "        print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The script for doing outlier detection using different score\n",
    "\"\"\"\n",
    "import argparse\n",
    "from model import VAE\n",
    "from loss import VAELoss\n",
    "from dataloader import load_vae_test_datasets, load_vae_train_datasets\n",
    "import os\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from itertools import product\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--model_path', required=True, type=str)\n",
    "parser.add_argument('--data', required=True, type=str)\n",
    "parser.add_argument('--image_size', default=256, type=int)\n",
    "parser.add_argument('--cuda', action='store_true')\n",
    "parser.add_argument('--kl_weight', type=float, default=1,\n",
    "                    help=\"weight on KL term\")\n",
    "parser.add_argument('--out_csv', default='result.csv')\n",
    "args = parser.parse_args()\n",
    "\n",
    "# load checkpoint\n",
    "if not os.path.isfile(args.model_path):\n",
    "    print('%s is not path to a file' % args.model_path)\n",
    "    exit()\n",
    "checkpoint = torch.load(args.model_path, map_location=lambda storage, loc: storage)\n",
    "print(\"checkpoint loaded!\")\n",
    "print(\"val loss: {}\\tepoch: {}\\t\".format(checkpoint['val_loss'], checkpoint['epoch']))\n",
    "\n",
    "# model and criterion\n",
    "model = VAE(args.image_size)\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "criterion = VAELoss(size_average=True, kl_weight=args.kl_weight)\n",
    "\n",
    "if args.cuda:\n",
    "    model = model.cuda()\n",
    "    criterion = criterion.cuda()\n",
    "\n",
    "# load data\n",
    "test_loader = load_vae_test_datasets(args.image_size, args.data)\n",
    "\n",
    "############################# ANOMALY SCORE DEF ##########################\n",
    "def get_vae_score(vae, image, L=5):\n",
    "    \"\"\"\n",
    "    The vae score for a single image, which is basically the loss\n",
    "    :param image: [1, 3, 256, 256]\n",
    "    :return (vae loss, KL, reconst_err)\n",
    "    \"\"\"\n",
    "    image_batch = image.expand(L,\n",
    "                               image.size(1),\n",
    "                               image.size(2),\n",
    "                               image.size(3))\n",
    "    reconst_batch, mu, logvar = vae.forward(image_batch)\n",
    "    vae_loss, loss_details = criterion(reconst_batch, image_batch, mu, logvar)\n",
    "    return vae_loss, loss_details['KL'], -loss_details['reconst_logp']\n",
    "\n",
    "def _log_mean_exp(x, dim):\n",
    "    \"\"\"\n",
    "    A numerical stable version of log(mean(exp(x)))\n",
    "    :param x: The input\n",
    "    :param dim: The dimension along which to take mean with\n",
    "    \"\"\"\n",
    "    # m [dim1, 1]\n",
    "    m, _ = torch.max(x, dim=dim, keepdim=True)\n",
    "\n",
    "    # x0 [dm1, dim2]\n",
    "    x0 = x - m\n",
    "\n",
    "    # m [dim1]\n",
    "    m = m.squeeze(dim)\n",
    "\n",
    "    return m + torch.log(torch.mean(torch.exp(x0),\n",
    "                                    dim=dim))\n",
    "\n",
    "def get_iwae_score(vae, image, L=5):\n",
    "    \"\"\"\n",
    "    The vae score for a single image, which is basically the loss\n",
    "    :param image: [1, 3, 256, 256]\n",
    "    :return scocre: (iwae score, iwae KL, iwae reconst).\n",
    "    \"\"\"\n",
    "    # [L, 3, 256, 256]\n",
    "    image_batch = image.expand(L,\n",
    "                               image.size(1),\n",
    "                               image.size(2),\n",
    "                               image.size(3))\n",
    "\n",
    "    # [L, z_dim, 1, 1]\n",
    "    mu, logvar = vae.encode(image_batch)\n",
    "    eps = torch.randn_like(mu)\n",
    "    z = mu + eps * torch.exp(0.5 * logvar)\n",
    "    kl_weight = criterion.kl_weight\n",
    "    # [L, 3, 256, 256]\n",
    "    reconst = vae.decode(z)\n",
    "    # [L]\n",
    "    log_p_x_z = -torch.sum((reconst - image_batch).pow(2).reshape(L, -1),\n",
    "                          dim=1)\n",
    "\n",
    "    # [L]\n",
    "    log_p_z = -torch.sum(z.pow(2).reshape(L, -1), dim=1)\n",
    "\n",
    "    # [L]\n",
    "    log_q_z = -torch.sum(eps.pow(2).reshape(L, -1), dim=1)\n",
    "\n",
    "    iwae_score = -_log_mean_exp(log_p_x_z + (log_p_z - log_q_z)*kl_weight, dim=0)\n",
    "    iwae_KL_score = -_log_mean_exp(log_p_z - log_q_z, dim=0)\n",
    "    iwae_reconst_score = -_log_mean_exp(log_p_x_z, dim=0)\n",
    "\n",
    "    return iwae_score, iwae_KL_score, iwae_reconst_score\n",
    "\n",
    "############################# END OF ANOMALY SCORE ###########################\n",
    "\n",
    "# Define the number of samples of each score\n",
    "def compute_all_scores(vae, image):\n",
    "    \"\"\"\n",
    "    Given an image compute all anomaly score\n",
    "    return (reconst_score, vae_score, iwae_score)\n",
    "    \"\"\"\n",
    "    vae_loss, KL, reconst_err = get_vae_score(vae, image=image, L=15)\n",
    "    iwae_loss, iwae_KL, iwae_reconst = get_iwae_score(vae, image, L=15)\n",
    "    result = {'reconst_score': reconst_err.item(),\n",
    "              'KL_score': KL.item(),\n",
    "              'vae_score': vae_loss.item(),\n",
    "              'iwae_score': iwae_loss.item(),\n",
    "              'iwae_KL_score': iwae_KL.item(),\n",
    "              'iwae_reconst_score': iwae_reconst.item()}\n",
    "    return result\n",
    "\n",
    "\n",
    "# MAIN LOOP\n",
    "score_names = ['reconst_score', 'KL_score', 'vae_score',\n",
    "               'iwae_reconst_score', 'iwae_KL_score', 'iwae_score']\n",
    "classes = test_loader.dataset.classes\n",
    "scores = {(score_name, cls): [] for (score_name, cls) in product(score_names,\n",
    "                                                                 classes)}\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for idx, (image, target) in tqdm(enumerate(test_loader)):\n",
    "        cls = classes[target.item()]\n",
    "        if args.cuda:\n",
    "            image = image.cuda()\n",
    "\n",
    "        score = compute_all_scores(vae=model, image=image)\n",
    "        for name in score_names:\n",
    "            scores[(name, cls)].append(score[name])\n",
    "\n",
    "# display the mean of scores\n",
    "means = np.zeros([len(score_names), len(classes)])\n",
    "for (name, cls) in product(score_names, classes):\n",
    "    means[score_names.index(name), classes.index(cls)] = sum(scores[(name, cls)]) / len(scores[(name, cls)])\n",
    "df_mean = pd.DataFrame(means, index=score_names, columns=classes)\n",
    "print(\"###################### MEANS #####################\")\n",
    "print(df_mean)\n",
    "\n",
    "\n",
    "classes.remove('NV')\n",
    "auc_result = np.zeros([len(score_names), len(classes) + 1])\n",
    "# get auc roc for each class\n",
    "for (name, cls) in product(score_names, classes):\n",
    "    normal_scores = scores[(name, 'NV')]\n",
    "    abnormal_scores = scores[(name, cls)]\n",
    "    y_true = [0]*len(normal_scores) + [1]*len(abnormal_scores)\n",
    "    y_score = normal_scores + abnormal_scores\n",
    "    auc_result[score_names.index(name), classes.index(cls)] = roc_auc_score(y_true, y_score)\n",
    "\n",
    "# add auc roc against all diseases\n",
    "for name in score_names:\n",
    "    normal_scores = scores[(name, 'NV')]\n",
    "    abnormal_scores = np.concatenate([scores[(name, cls)]for cls in classes]).tolist()\n",
    "    y_true = [0]*len(normal_scores) + [1]*len(abnormal_scores)\n",
    "    y_score = normal_scores + abnormal_scores\n",
    "    auc_result[score_names.index(name), -1] = roc_auc_score(y_true, y_score)\n",
    "\n",
    "df = pd.DataFrame(auc_result, index=score_names, columns=classes + ['ALL'])\n",
    "# display\n",
    "print(\"###################### AUC ROC #####################\")\n",
    "print(df)\n",
    "print(\"####################################################\")\n",
    "df.to_csv(args.out_csv)\n",
    "\n",
    "# fit a gamma distribution\n",
    "_, val_loader = load_vae_train_datasets(args.image_size, args.data, 32)\n",
    "model.eval()\n",
    "all_reconst_err = []\n",
    "num_val = len(val_loader.dataset)\n",
    "with torch.no_grad():\n",
    "    for img, _ in tqdm(val_loader):\n",
    "        if args.cuda:\n",
    "            img = img.cuda()\n",
    "\n",
    "        # compute output\n",
    "        recon_batch, mu, logvar = model(img)\n",
    "        loss, loss_details = criterion.forward_without_reduce(recon_batch, img, mu, logvar)\n",
    "        reconst_err = -loss_details['reconst_logp']\n",
    "        all_reconst_err += reconst_err.tolist()\n",
    "\n",
    "fit_alpha, fit_loc, fit_beta=stats.gamma.fit(all_reconst_err)\n",
    "\n",
    "# using gamma for outlier detection\n",
    "# get auc roc for each class\n",
    "LARGE_NUMBER = 1e30\n",
    "\n",
    "def get_gamma_score(scores):\n",
    "    result = -stats.gamma.logpdf(scores, fit_alpha, fit_loc, fit_beta)\n",
    "    # replace inf in result with largest number\n",
    "    result[result == np.inf] = LARGE_NUMBER\n",
    "    return result\n",
    "\n",
    "auc_gamma_result = np.zeros([1, len(classes)+1])\n",
    "name = 'reconst_score'\n",
    "for cls in classes:\n",
    "    normal_scores = get_gamma_score(scores[(name, 'NV')]).tolist()\n",
    "    abnormal_scores = get_gamma_score(scores[(name, cls)]).tolist()\n",
    "    y_true = [0]*len(normal_scores) + [1]*len(abnormal_scores)\n",
    "    y_score = normal_scores + abnormal_scores\n",
    "    auc_gamma_result[0, classes.index(cls)] = roc_auc_score(y_true, y_score)\n",
    "\n",
    "# for all class\n",
    "normal_scores = get_gamma_score(scores[(name, 'NV')]).tolist()\n",
    "abnormal_scores = np.concatenate([get_gamma_score(scores[(name, cls)]) for cls in classes]).tolist()\n",
    "y_true = [0]*len(normal_scores) + [1]*len(abnormal_scores)\n",
    "y_score = normal_scores + abnormal_scores\n",
    "auc_gamma_result[0, -1] = roc_auc_score(y_true, y_score)\n",
    "df = pd.DataFrame(auc_gamma_result, index=['gamma score'], columns=classes + ['ALL'])\n",
    "\n",
    "# display\n",
    "print(\"###################### AUC ROC GAMMA #####################\")\n",
    "print(df)\n",
    "print(\"##########################################################\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
